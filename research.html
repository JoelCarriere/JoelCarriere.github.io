<!DOCTYPE html>


<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ" crossorigin="anonymous">
    <title>Joel Carriere</title>
    <link type="text/css" rel="stylesheet" href="/docs/assets/css/style.css"/>
    <link rel="apple-touch-icon" sizes="180x180" href="docs/assets/img/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="docs/assets/img/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="docs/assets/img/favicon-16x16.png">
    <link rel="manifest" href="docs/assets/img/site.webmanifest">
    <link rel="mask-icon" href="docs/assets/img/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
  </head>

  <body>
    <div class="header">
      <div class="left">
        <div id="header-logo"><img src="./docs/assets/img/site-logo-white.svg">
        </div>
      </div>
      <div class="right">
        <ul class="pages">
          <li><a href="https://joelcarriere.com">Home</a></li>
          <li><a href="research.html">Research</a></li>
          <li><a href="resume.html">Resume</a></li>
        </ul>
      </div>
    </div>
    
    <main>
          <div class="container">
            <div>
              <h3>Machine Learning Projects</h3>
              <p>
                My main focus is on using open-source
                algorithms and off-the-shelf cameras to
                determine human wrist kinematics. 
                Designing experiments, creating datasets,
                and refining model parameters has lead me
                to a high-degree of success in this.
                The video illustrates a 3D markerset
                generated through 2D videos and computer vision techniques.
                The green segment seen represents markers placed 
                on a subjects knuckles and the blue segment represents
                markers on their wrist. The orange segment is a connection
                representing the movement of the hand in relation to the
                wrist. 
              </p>
              <video id="rom-video" preload="auto" autoplay loop muted>
                <source src="/docs/assets/img/rom-video.mp4" type=video/mp4>
              </video>
              <p>
                Laboratory experiments were conducted to build the dataset that 
                was used in training a wrist angle prediction model. 
                A gold-standard motion capture system was used alongside 
                off-the-shelf cameras to build a dataset that contained 
                marker locations with ground-truth wrist angles. 
                I have successfully achieved a high-degree of accuracy
                when using both a multi-camera and single camera approach
                to solving this issue. Through the use of deep neural networks,
                I was able to achieve an angular value with a mean
                absolute error of approximately 5 degrees when compared to the current gold-standard. 
              </p>
              <hr>
              <p>
                Another project involved using CNNs to detect faces within photos
                and then predict the race and gender of the subject. This was 
                completed by using YOLOv5 to detect subject faces within several
                open-source datasets, and crop out the face without the surroundings. 
                The cropped faces were used to train a pre-trained ResNet-34 network
                to be able to predict the subject race and gender. Gender classification 
                achieved 99% accuracy and race prediction achieved up to 95% accuracy.
              </p>
              <hr>
              <p>
                Designed experiments to evaluate machine learning models on a 
                multi-modal human action dataset achieving an F1 score of 0.90
                in classifying 21 upper body motions related to biomechanical
                movement.
              </p>
            </div>
          </div>
      </main>
      <br>
      <br>
      <div class="footer">
        <ul class="footer-logos">
          <li>
            <a href="tel: 17053096860">
                <img class="logo-image" src="./docs/assets/img/cellphone.svg">
            </a>
          </li>
          <li>
            <a href="mailto: j-carriere@live.ca">
                <img class="logo-image" src="./docs/assets/img/email-outline.svg">
            </a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/joelcarriere">
                <img class="logo-image" src="./docs/assets/img/linkedin.png">
            </a>
          </li>
        </ul>
      </div>
      <br>
      <br>
</body>
</html>
